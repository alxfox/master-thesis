image_size: [256, 704]

model:
  decoder:
    backbone:
      type: GeneralizedResNet
      in_channels: 256
      blocks:
        - [2, 128, 2]
        - [2, 256, 2]
        - [2, 512, 1]
    neck:
      type: LSSFPN
      in_indices: [-1, 0]
      in_channels: [512, 128]
      out_channels: 256
      scale_factor: 2
  heads:
    object:
      test_cfg:
        nms_type:
          - circle
          - rotate
          - rotate
          - circle
          - rotate
          - rotate
        nms_scale:
          - [1.0]
          - [1.0, 1.0]
          - [1.0, 1.0]
          - [1.0]
          - [1.0, 1.0]
          - [2.5, 4.0]
  # encoders:
    # lidar:
    #   voxelize:
    #     max_num_points: 10
    #     point_cloud_range: ${point_cloud_range}
    #     voxel_size: ${voxel_size}
    #     max_voxels: [90000, 120000]
    #   backbone:
    #     type: SparseEncoder
    #     in_channels: 5
    #     sparse_shape: [1024, 1024, 41]
    #     output_channels: 128
    #     order:
    #       - conv
    #       - norm
    #       - act
    #     encoder_channels:
    #       - [16, 16, 32]
    #       - [32, 32, 64]
    #       - [64, 64, 128]
    #       - [128, 128]
    #     encoder_paddings:
    #       - [0, 0, 1]
    #       - [0, 0, 1]
    #       - [0, 0, [1, 1, 0]]
    #       - [0, 0]
    #     block_type: basicblock

data:
  samples_per_gpu: 8
  workers_per_gpu: 8

optimizer:
  type: AdamW
  lr: 1.0e-4
  weight_decay: 0.01

optimizer_config:
  grad_clip:
    max_norm: 35
    norm_type: 2

lr_config: null